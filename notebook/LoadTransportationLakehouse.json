{
	"name": "LoadTransportationLakehouse",
	"properties": {
		"folder": {
			"name": "LoadLakeDatabases"
		},
		"nbformat": 4,
		"nbformat_minor": 0,
		"bigDataPool": {
			"referenceName": "default",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"conf": {
				"spark.livy.synapse.ipythonInterpreter.enabled": "true"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "python3",
				"display_name": "Python 3.10.0 64-bit"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/trident/default",
				"name": "default",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				}
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"azdata_cell_guid": "909dd6b8-c69e-4790-bd0f-810cea4aefaf",
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Transportation"
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"azdata_cell_guid": "56b21c71-568f-4004-89c6-54bf54832a65",
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## NYC Taxi & Limousine Commission - yellow taxi trip records\n",
					"\n",
					"The yellow taxi trip records include fields capturing pick-up and drop-off dates/times, pick-up and drop-off locations, trip distances, itemized fares, rate types, payment types, and driver-reported passenger counts."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"azdata_cell_guid": "f3c50892-951d-423a-bb79-2280aedccdd6",
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"language": "python",
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Azure storage access info\n",
					"blob_account_name = \"azureopendatastorage\"\n",
					"blob_container_name = \"nyctlc\"\n",
					"blob_relative_path = \"yellow\"\n",
					"blob_sas_token = r\"\"\n",
					"\n",
					"# Allow SPARK to read from Blob remotely\n",
					"wasbs_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path)\n",
					"spark.conf.set(\n",
					"  'fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name),\n",
					"  blob_sas_token)\n",
					"print('Remote blob path: ' + wasbs_path)\n",
					"\n",
					"# SPARK read parquet, note that it won't load any data yet by now\n",
					"df = spark.read.parquet(wasbs_path)\n",
					"df.write.format(\"delta\").saveAsTable(\"yellow_taxi\")"
				],
				"execution_count": 1
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"azdata_cell_guid": "c7fd6d0e-addf-4d9a-93f7-cd897d68bdd6",
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## NYC Taxi & Limousine Commission - green taxi trip records\n",
					"\n",
					"The green taxi trip records include fields capturing pick-up and drop-off dates/times, pick-up and drop-off locations, trip distances, itemized fares, rate types, payment types, and driver-reported passenger counts."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"azdata_cell_guid": "ea100fb0-63b1-4108-b1cd-506b21045d5e",
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"language": "python",
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Azure storage access info\n",
					"blob_account_name = \"azureopendatastorage\"\n",
					"blob_container_name = \"nyctlc\"\n",
					"blob_relative_path = \"green\"\n",
					"blob_sas_token = r\"\"\n",
					"\n",
					"# Allow SPARK to read from Blob remotely\n",
					"wasbs_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path)\n",
					"spark.conf.set(\n",
					"  'fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name),\n",
					"  blob_sas_token)\n",
					"print('Remote blob path: ' + wasbs_path)\n",
					"\n",
					"# SPARK read parquet, note that it won't load any data yet by now\n",
					"df = spark.read.parquet(wasbs_path)\n",
					"df.write.format(\"delta\").saveAsTable(\"green_taxi\")"
				],
				"execution_count": 2
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"azdata_cell_guid": "77313fbf-687a-4aaa-8494-96409bfc6967",
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## NYC Taxi & Limousine Commission - For-Hire Vehicle (FHV) trip records\n",
					"\n",
					"The For-Hire Vehicle (“FHV”) trip records include fields capturing the dispatching base license number and the pick-up date, time, and taxi zone location ID (shape file below). These records are generated from the FHV Trip Record submissions made by bases."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"azdata_cell_guid": "a5955fb7-8f2b-471d-9c5b-f9164c1b330e",
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"language": "python",
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Azure storage access info\n",
					"blob_account_name = \"azureopendatastorage\"\n",
					"blob_container_name = \"nyctlc\"\n",
					"blob_relative_path = \"fhv\"\n",
					"blob_sas_token = r\"\"\n",
					"\n",
					"# Allow SPARK to read from Blob remotely\n",
					"wasbs_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path)\n",
					"spark.conf.set(\n",
					"  'fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name),\n",
					"  blob_sas_token)\n",
					"print('Remote blob path: ' + wasbs_path)\n",
					"\n",
					"# SPARK read parquet, note that it won't load any data yet by now\n",
					"df = spark.read.parquet(wasbs_path)\n",
					"df.write.format(\"delta\").saveAsTable(\"for_hire_vehicle\")"
				],
				"execution_count": 5
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"azdata_cell_guid": "28505d38-ad93-4f58-b6ab-f1fbf2c0fce6",
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Chicago Safety Data\n",
					"\n",
					"311 service requests from the city of Chicago, including historical sanitation code complaints, pot holes reported, and street light issues"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"azdata_cell_guid": "5acbc6f3-3372-4c18-86cd-e7c24ac2a4c0",
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"language": "python",
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Azure storage access info\n",
					"blob_account_name = \"azureopendatastorage\"\n",
					"blob_container_name = \"citydatacontainer\"\n",
					"blob_relative_path = \"Safety/Release/city=Chicago\"\n",
					"blob_sas_token = r\"\"\n",
					"\n",
					"# Allow SPARK to read from Blob remotely\n",
					"wasbs_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path)\n",
					"spark.conf.set(\n",
					"  'fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name),\n",
					"  blob_sas_token)\n",
					"print('Remote blob path: ' + wasbs_path)\n",
					"\n",
					"df = spark.read.parquet(wasbs_path)\n",
					"df.write.format(\"delta\").saveAsTable(\"chicago_safety_data\")"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"azdata_cell_guid": "e3bc971c-7ec5-49e9-a9d4-d3ea4b3992d1",
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## San Francisco Safety Data\n",
					"\n",
					"Fire department calls for service and 311 cases in San Francisco."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"azdata_cell_guid": "abcde903-5f73-4e0e-866e-614b489ca596",
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"language": "python",
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Azure storage access info\n",
					"blob_account_name = \"azureopendatastorage\"\n",
					"blob_container_name = \"citydatacontainer\"\n",
					"blob_relative_path = \"Safety/Release/city=SanFrancisco\"\n",
					"blob_sas_token = r\"\"\n",
					"\n",
					"# Allow SPARK to read from Blob remotely\n",
					"wasbs_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path)\n",
					"spark.conf.set(\n",
					"  'fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name),\n",
					"  blob_sas_token)\n",
					"print('Remote blob path: ' + wasbs_path)\n",
					"\n",
					"df = spark.read.parquet(wasbs_path)\n",
					"df.write.format(\"delta\").saveAsTable(\"san_francisco_safety_data\")"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"azdata_cell_guid": "338dafdd-83ae-4d56-b566-02682dfc79df",
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Seattle Safety Data\n",
					"\n",
					"Seattle Fire Department 911 dispatches."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"azdata_cell_guid": "a7e885b8-1183-4f36-9d32-faaa9af08f41",
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"language": "python",
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Azure storage access info\n",
					"blob_account_name = \"azureopendatastorage\"\n",
					"blob_container_name = \"citydatacontainer\"\n",
					"blob_relative_path = \"Safety/Release/city=Seattle\"\n",
					"blob_sas_token = r\"\"\n",
					"\n",
					"# Allow SPARK to read from Blob remotely\n",
					"wasbs_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path)\n",
					"spark.conf.set(\n",
					"  'fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name),\n",
					"  blob_sas_token)\n",
					"print('Remote blob path: ' + wasbs_path)\n",
					"\n",
					"df = spark.read.parquet(wasbs_path)\n",
					"df.write.format(\"delta\").saveAsTable(\"seattle_safety_data\")"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"azdata_cell_guid": "b00916dc-e3d6-4a4e-85b3-5e8509e06668",
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Boston Safety Data\n",
					"\n",
					"311 calls reported to the city of Boston."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"azdata_cell_guid": "c33914fd-7d86-48a8-b946-f64599a1d51a",
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"language": "python",
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Azure storage access info\n",
					"blob_account_name = \"azureopendatastorage\"\n",
					"blob_container_name = \"citydatacontainer\"\n",
					"blob_relative_path = \"Safety/Release/city=Boston\"\n",
					"blob_sas_token = r\"\"\n",
					"\n",
					"# Allow SPARK to read from Blob remotely\n",
					"wasbs_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path)\n",
					"spark.conf.set(\n",
					"  'fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name),\n",
					"  blob_sas_token)\n",
					"print('Remote blob path: ' + wasbs_path)\n",
					"\n",
					"df = spark.read.parquet(wasbs_path)\n",
					"df.write.format(\"delta\").saveAsTable(\"boston_safety_data\")"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"azdata_cell_guid": "66f161ef-fa48-48c5-a3f7-d656542ac5d5",
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## US Population by ZIP code\n",
					"\n",
					"US population by gender and race for each US ZIP code sourced from 2000 and 2010 Decennial Census.\n",
					"\n",
					"This dataset is sourced from United States Census Bureau’s Decennial Census Dataset APIs. Review Terms of Service and Policies and Notices for the terms and conditions related to the use this dataset."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"azdata_cell_guid": "376194fe-3fcc-44b1-90b1-229c771582bc",
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"language": "python",
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Azure storage access info\n",
					"blob_account_name = \"azureopendatastorage\"\n",
					"blob_container_name = \"censusdatacontainer\"\n",
					"blob_relative_path = \"release/us_population_zip/\"\n",
					"blob_sas_token = r\"\"\n",
					"\n",
					"# Allow SPARK to read from Blob remotely\n",
					"wasbs_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path)\n",
					"spark.conf.set(\n",
					"  'fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name),\n",
					"  blob_sas_token)\n",
					"print('Remote blob path: ' + wasbs_path)\n",
					"\n",
					"df = spark.read.parquet(wasbs_path)\n",
					"df.write.format(\"delta\").saveAsTable(\"us_population_zip\")\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"azdata_cell_guid": "f89265a3-b971-4b90-b0c0-6f7b05ae7c86",
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## US Population by County\n",
					"\n",
					"US population by gender and race for each US county sourced from 2000 and 2010 Decennial Census.\n",
					"\n",
					"This dataset is sourced from United States Census Bureau’s Decennial Census Dataset APIs. Review Terms of Service and Policies and Notices for the terms and conditions related to the use this dataset."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"azdata_cell_guid": "730b6e51-2e17-47af-850e-56bcc172c020",
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"language": "python",
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Azure storage access info\n",
					"blob_account_name = \"azureopendatastorage\"\n",
					"blob_container_name = \"censusdatacontainer\"\n",
					"blob_relative_path = \"release/us_population_county/\"\n",
					"blob_sas_token = r\"\"\n",
					"\n",
					"# Allow SPARK to read from Blob remotely\n",
					"wasbs_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path)\n",
					"spark.conf.set(\n",
					"  'fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name),\n",
					"  blob_sas_token)\n",
					"print('Remote blob path: ' + wasbs_path)\n",
					"\n",
					"df = spark.read.parquet(wasbs_path)\n",
					"df.write.format(\"delta\").saveAsTable(\"us_population_county\")"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"azdata_cell_guid": "9aaabcab-7e09-411e-9bea-ca430cc005dc",
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Common datasets"
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"azdata_cell_guid": "6f46c3c9-51a5-4323-87b6-e9b87dec6662",
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Public Holidays\n",
					"\n",
					"Worldwide public holiday data sourced from PyPI holidays package and Wikipedia, covering 38 countries or regions from 1970 to 2099."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"azdata_cell_guid": "f833d2e4-25fe-49da-b283-764dca14ab44",
					"jupyter": {
						"outputs_hidden": false,
						"source_hidden": false
					},
					"language": "python",
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Azure storage access info\n",
					"blob_account_name = \"azureopendatastorage\"\n",
					"blob_container_name = \"holidaydatacontainer\"\n",
					"blob_relative_path = \"Processed\"\n",
					"blob_sas_token = r\"\"\n",
					"\n",
					"# Allow SPARK to read from Blob remotely\n",
					"wasbs_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path)\n",
					"spark.conf.set(\n",
					"  'fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name),\n",
					"  blob_sas_token)\n",
					"print('Remote blob path: ' + wasbs_path)\n",
					"\n",
					"df = spark.read.parquet(wasbs_path)\n",
					"df.write.format(\"delta\").saveAsTable(\"public_holidays\")"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"## US Population by County\n",
					"\n",
					"US population by gender and race for each US county sourced from 2000 and 2010 Decennial Census.\n",
					"\n",
					"This dataset is sourced from United States Census Bureau’s Decennial Census Dataset APIs. Review Terms of Service and Policies and Notices for the terms and conditions related to the use this dataset."
				]
			},
			{
				"cell_type": "code",
				"source": [
					"# Azure storage access info\n",
					"blob_account_name = \"azureopendatastorage\"\n",
					"blob_container_name = \"censusdatacontainer\"\n",
					"blob_relative_path = \"release/us_population_county/\"\n",
					"blob_sas_token = r\"\"\n",
					"\n",
					"# Allow SPARK to read from Blob remotely\n",
					"wasbs_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path)\n",
					"spark.conf.set(\n",
					"  'fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name),\n",
					"  blob_sas_token)\n",
					"print('Remote blob path: ' + wasbs_path)\n",
					"\n",
					"df = spark.read.parquet(wasbs_path)\n",
					"df.write.format(\"delta\").saveAsTable(\"us_population_county\")"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"## US Population by ZIP code\n",
					"\n",
					"US population by gender and race for each US ZIP code sourced from 2000 and 2010 Decennial Census.\n",
					"\n",
					"This dataset is sourced from United States Census Bureau’s Decennial Census Dataset APIs. Review Terms of Service and Policies and Notices for the terms and conditions related to the use this dataset."
				]
			},
			{
				"cell_type": "code",
				"source": [
					"# Azure storage access info\n",
					"blob_account_name = \"azureopendatastorage\"\n",
					"blob_container_name = \"censusdatacontainer\"\n",
					"blob_relative_path = \"release/us_population_zip/\"\n",
					"blob_sas_token = r\"\"\n",
					"\n",
					"# Allow SPARK to read from Blob remotely\n",
					"wasbs_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path)\n",
					"spark.conf.set(\n",
					"  'fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name),\n",
					"  blob_sas_token)\n",
					"print('Remote blob path: ' + wasbs_path)\n",
					"\n",
					"df = spark.read.parquet(wasbs_path)\n",
					"df.write.format(\"delta\").saveAsTable(\"us_population_zip\")\n",
					""
				],
				"execution_count": null
			}
		]
	}
}