{
	"name": "HC Incremental Copy from On-prem SQL Spark_copy1",
	"properties": {
		"description": "using Spark",
		"activities": [
			{
				"name": "Extract as Parquet to Data Lake",
				"type": "Copy",
				"dependsOn": [],
				"policy": {
					"timeout": "0.12:00:00",
					"retry": 0,
					"retryIntervalInSeconds": 30,
					"secureOutput": false,
					"secureInput": false
				},
				"userProperties": [],
				"typeProperties": {
					"source": {
						"type": "AzureSqlSource",
						"queryTimeout": "02:00:00",
						"partitionOption": "None"
					},
					"sink": {
						"type": "ParquetSink",
						"storeSettings": {
							"type": "AzureBlobFSWriteSettings"
						},
						"formatSettings": {
							"type": "ParquetWriteSettings"
						}
					},
					"enableStaging": false,
					"translator": {
						"type": "TabularTranslator",
						"typeConversion": true,
						"typeConversionSettings": {
							"allowDataTruncation": true,
							"treatBooleanAsNumber": false
						}
					}
				},
				"inputs": [
					{
						"referenceName": "SqlTable",
						"type": "DatasetReference"
					}
				],
				"outputs": [
					{
						"referenceName": "sales_history",
						"type": "DatasetReference"
					}
				]
			},
			{
				"name": "Incremental Load to Delta Lake Bronze",
				"type": "SynapseNotebook",
				"dependsOn": [
					{
						"activity": "Extract as Parquet to Data Lake",
						"dependencyConditions": [
							"Succeeded"
						]
					}
				],
				"policy": {
					"timeout": "0.12:00:00",
					"retry": 0,
					"retryIntervalInSeconds": 30,
					"secureOutput": false,
					"secureInput": false
				},
				"userProperties": [],
				"typeProperties": {
					"notebook": {
						"referenceName": "TransactionHistory Delta Incremental Load",
						"type": "NotebookReference"
					},
					"parameters": {
						"": {
							"value": ""
						}
					},
					"snapshot": true,
					"sparkPool": {
						"referenceName": "sparkpool1",
						"type": "BigDataPoolReference"
					},
					"executorSize": "Small",
					"conf": {
						"spark.dynamicAllocation.enabled": false,
						"spark.dynamicAllocation.minExecutors": null,
						"spark.dynamicAllocation.maxExecutors": null
					},
					"driverSize": "Small",
					"numExecutors": null
				}
			},
			{
				"name": "Transform and write to Silver",
				"type": "SynapseNotebook",
				"dependsOn": [
					{
						"activity": "Incremental Load to Delta Lake Bronze",
						"dependencyConditions": [
							"Succeeded"
						]
					}
				],
				"policy": {
					"timeout": "0.12:00:00",
					"retry": 0,
					"retryIntervalInSeconds": 30,
					"secureOutput": false,
					"secureInput": false
				},
				"userProperties": [],
				"typeProperties": {
					"notebook": {
						"referenceName": "TransactionHistory Silver Transform",
						"type": "NotebookReference"
					},
					"snapshot": true,
					"sparkPool": {
						"referenceName": "sparkpool1",
						"type": "BigDataPoolReference"
					},
					"executorSize": "Small",
					"conf": {
						"spark.dynamicAllocation.enabled": false,
						"spark.dynamicAllocation.minExecutors": 3,
						"spark.dynamicAllocation.maxExecutors": 3
					},
					"driverSize": "Small",
					"numExecutors": 3
				}
			}
		],
		"folder": {
			"name": "Spark Incremental Files to Staging Ded SQL Pool"
		},
		"annotations": []
	}
}